{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 1. Setup Spark Session\n",
        "\n"
      ],
      "metadata": {
        "id": "EaBDncvlBdIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy0pmijxAdo-"
      },
      "outputs": [],
      "source": [
        "# Install PySpark in Colab if needed\n",
        "# !pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"HealthcareClaimsFraudDetection\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 2. Simulate Claims Data\n",
        "\n"
      ],
      "metadata": {
        "id": "0GfGgk2Ab5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "import random\n",
        "\n",
        "# define schema\n",
        "claims_schema = StructType([\n",
        "    StructField(\"claim_id\", IntegerType(), True),\n",
        "    StructField(\"patient_id\", IntegerType(), True),\n",
        "    StructField(\"procedure_code\", StringType(), True),\n",
        "    StructField(\"amount\", DoubleType(), True),\n",
        "    StructField(\"claim_type\", StringType(), True),\n",
        "    StructField(\"date\", StringType(), True)\n",
        "])\n",
        "\n",
        "# generate 1 million rows (adjust to 10 million if you like, but this is faster for a demo)\n",
        "data = []\n",
        "procedures = [\"P100\", \"P200\", \"P300\", \"P400\", \"P500\", \"P600\", \"P700\"]\n",
        "claim_types = [\"inpatient\", \"outpatient\"]\n",
        "\n",
        "for i in range(1, 1000001):\n",
        "    data.append((\n",
        "        i,\n",
        "        random.randint(1, 50000),                      # patient_id\n",
        "        random.choice(procedures),                     # procedure_code\n",
        "        round(random.uniform(100, 5000), 2),           # amount\n",
        "        random.choice(claim_types),                    # claim_type\n",
        "        f\"2025-{random.randint(1,12):02d}-{random.randint(1,28):02d}\"  # date\n",
        "    ))\n",
        "\n",
        "claims_df = spark.createDataFrame(data, claims_schema)\n",
        "\n",
        "print(f\"Total claims rows: {claims_df.count()}\")\n",
        "claims_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MldyVjzkb-pa",
        "outputId": "5d86f1fe-8eee-4aaa-980b-9b1f44f27343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total claims rows: 1000000\n",
            "+--------+----------+--------------+-------+----------+----------+\n",
            "|claim_id|patient_id|procedure_code| amount|claim_type|      date|\n",
            "+--------+----------+--------------+-------+----------+----------+\n",
            "|       1|     23072|          P100|3414.35| inpatient|2025-05-06|\n",
            "|       2|      1078|          P700|4512.98|outpatient|2025-08-02|\n",
            "|       3|     25652|          P400|1248.88| inpatient|2025-11-08|\n",
            "|       4|       268|          P700|1356.94|outpatient|2025-02-08|\n",
            "|       5|     15091|          P300|4683.09|outpatient|2025-10-09|\n",
            "+--------+----------+--------------+-------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 3. Simulate Fraud Codes Lookup (Small Table)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "van7ZNsYcEZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_codes_data = [\n",
        "    (\"P100\", 1),\n",
        "    (\"P400\", 1),\n",
        "    (\"P600\", 1)\n",
        "]\n",
        "fraud_codes_schema = StructType([\n",
        "    StructField(\"procedure_code\", StringType(), True),\n",
        "    StructField(\"is_fraud\", IntegerType(), True)\n",
        "])\n",
        "fraud_codes_df = spark.createDataFrame(fraud_codes_data, fraud_codes_schema)\n",
        "\n",
        "fraud_codes_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1jnUKqxcQGw",
        "outputId": "e3c26660-0eab-4386-f023-8a0ae8827420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+\n",
            "|procedure_code|is_fraud|\n",
            "+--------------+--------+\n",
            "|          P100|       1|\n",
            "|          P400|       1|\n",
            "|          P600|       1|\n",
            "+--------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 4. Broadcast Join to Label Suspicious Claims\n"
      ],
      "metadata": {
        "id": "EdU63WLmcXik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "joined_df = claims_df.join(\n",
        "    broadcast(fraud_codes_df),\n",
        "    on=\"procedure_code\",\n",
        "    how=\"left\"\n",
        ").fillna(0, subset=[\"is_fraud\"])\n",
        "\n",
        "joined_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL_uCheQcb0b",
        "outputId": "9a196ef7-795b-4ab1-d50b-2361324058dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------+----------+-------+----------+----------+--------+\n",
            "|procedure_code|claim_id|patient_id| amount|claim_type|      date|is_fraud|\n",
            "+--------------+--------+----------+-------+----------+----------+--------+\n",
            "|          P100|       1|     23072|3414.35| inpatient|2025-05-06|       1|\n",
            "|          P700|       2|      1078|4512.98|outpatient|2025-08-02|       0|\n",
            "|          P400|       3|     25652|1248.88| inpatient|2025-11-08|       1|\n",
            "|          P700|       4|       268|1356.94|outpatient|2025-02-08|       0|\n",
            "|          P300|       5|     15091|4683.09|outpatient|2025-10-09|       0|\n",
            "+--------------+--------+----------+-------+----------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 5. Repartition by Claim Type\n",
        "\n"
      ],
      "metadata": {
        "id": "RX0WOVDMcjo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repartition for optimized writes or queries\n",
        "repartitioned_df = joined_df.repartition(\"claim_type\")\n",
        "\n",
        "print(\"Repartitioned by claim_type:\")\n",
        "print(repartitioned_df.rdd.getNumPartitions())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6RgdKX6cowJ",
        "outputId": "58812d3c-b5c7-4438-c1a4-9749e5bf4f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repartitioned by claim_type:\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 6. Cache High-Risk Claims\n",
        "\n"
      ],
      "metadata": {
        "id": "WpJ9zFsddPYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define \"high-risk\" as amount > 3000 and marked as fraud\n",
        "high_risk_df = joined_df.filter(\n",
        "    (F.col(\"amount\") > 3000) & (F.col(\"is_fraud\") == 1)\n",
        ")\n",
        "\n",
        "# Cache\n",
        "high_risk_df.cache()\n",
        "high_risk_df.count()  # triggers caching\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwBmgTqvdXgV",
        "outputId": "3d64b007-5968-445a-b972-17e69f93c4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175283"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 7. Apply MLlib KMeans for Anomaly Detection\n"
      ],
      "metadata": {
        "id": "BiJzImixdhxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "# convert to features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"amount\", \"patient_id\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "features_df = assembler.transform(high_risk_df)\n",
        "\n",
        "# train kmeans\n",
        "kmeans = KMeans(k=2, seed=42)\n",
        "model = kmeans.fit(features_df)\n",
        "\n",
        "predictions = model.transform(features_df)\n",
        "\n",
        "# show cluster assignments\n",
        "predictions.select(\"claim_id\", \"amount\", \"patient_id\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Kpql0IdlY8",
        "outputId": "75c14c6e-d2ca-46f8-ae18-8e633e6bc99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----------+----------+\n",
            "|claim_id| amount|patient_id|prediction|\n",
            "+--------+-------+----------+----------+\n",
            "|       1|3414.35|     23072|         1|\n",
            "|       7|3502.39|     26250|         0|\n",
            "|      10|3491.61|     32202|         0|\n",
            "|      14|3070.75|     15097|         1|\n",
            "|      21|3388.29|     33785|         0|\n",
            "|      34| 4623.3|     47375|         0|\n",
            "|      35|4557.71|     35195|         0|\n",
            "|      36|4429.94|     22586|         1|\n",
            "|      38|3695.54|     15748|         1|\n",
            "|      39|3033.51|      2821|         1|\n",
            "+--------+-------+----------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vmRhralOdgHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìÅ 8. Analyze Cluster Centers\n",
        "\n"
      ],
      "metadata": {
        "id": "q_0ni31MdrvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cluster Centers:\")\n",
        "for center in model.clusterCenters():\n",
        "    print(center)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iACWTUm2d1Gp",
        "outputId": "0bd205ce-fcf4-4d42-a494-ecefe00223f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:\n",
            "[ 3997.81570898 37490.00311001]\n",
            "[ 3999.34773079 12537.70936664]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìÅ 9. Done!\n",
        "\n"
      ],
      "metadata": {
        "id": "oH2xx412d5m1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "O9CU3x25eFbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}